For the given sql files, your job is to develope etl pipeline with python that extracts data from oltp solution to olap solution. The output should be only in python text box. DONT EXPLAIN DONT ADD NOTES. ALSO, MAKE SURE TO COVER ALL THE TABLES IN THE OLAP SOLUTION. Here is full task:
2.2 Develop ETL process to move
data from OLTP database to
OLAP database
REQUIREMENTS:
Script for ETL should be rerunnable, Previously added data
should not be rewritten
2.2 Develop ETL
process to move
data from OLTP
database to OLAP
database â€“ check
which OLTP data
were already
uploaded and add
only new ones,
made
transformations if
needed, save data
to DWH
Script Theory:
ETL, which stands for extract, transform, and load, is the
process data engineers use to extract data from different
sources, transform the data into a usable and trusted resource,
and load that data into the systems end-users can access and
use downstream to solve business problems.
ToDo:
You can use any programming language or software solution for
development of an ETL pipeline.
Example:
1. Identify reference OLTP data: write a query/few queries that
defines the set of permissible values your DWH may contain.
For example, in a country data field, specify the list of country
codes allowed.
2. Extract data from the source: convert it into a single format
for standardized processing.
3. Validate data: keep data that have values in the expected
ranges and reject any that do not. For example, if you only want
dates from the last year, reject any values older than 12
months.
4. Transform data: remove duplicate data (cleaning), apply
business rules, check data integrity (ensure that data has not
been corrupted or lost), and create aggregates as necessary. For
example, if you want to analyze revenue, you can summarize
the dollar amount of invoices into a daily or monthly total. You
may need to program numerous functions to transform the
data automatically.
5. Stage data (optional): sometimes it is better not to load
transformed data directly into the target data warehouse.
Instead, data first enters a staging database which makes it
easier to roll back if something goes wrong.
6. Publish data to your data warehouse: load data to the target
tables
the code(oltp):
```
CREATE TABLE "user" (
    userid int PRIMARY KEY,
    username varchar(255),
    email varchar(255),
    password varchar(255)
);

-- Creating the artist table
CREATE TABLE "artist" (
    artistid int PRIMARY KEY,
    name varchar(255),
    genre varchar(255)
);

-- Creating the album table
CREATE TABLE "album" (
    albumid int PRIMARY KEY,
    title varchar(255),
    artistid int,
    genre varchar(255),
    releasedate date,
    FOREIGN KEY (artistid) REFERENCES "artist"(artistid)
);

-- Creating the track table
CREATE TABLE "track" (
    trackid int PRIMARY KEY,
    title varchar(255),
    artistid int,
    albumid int,
    duration time,
    releasedate date,
    FOREIGN KEY (artistid) REFERENCES "artist"(artistid),
    FOREIGN KEY (albumid) REFERENCES "album"(albumid)
);

-- Creating the playlist table
CREATE TABLE "playlist" (
    playlistid int PRIMARY KEY,
    userid int,
    title varchar(255),
    creationdate date,
    FOREIGN KEY (userid) REFERENCES "user"(userid)
);

-- Creating the like table
CREATE TABLE "like" (
    likeid int PRIMARY KEY,
    userid int,
    trackid int,
    FOREIGN KEY (userid) REFERENCES "user"(userid),
    FOREIGN KEY (trackid) REFERENCES "track"(trackid)
);

-- Creating the premium feature table
CREATE TABLE "premiumfeature" (
    premium_feature_id int PRIMARY KEY,
    name varchar(255)
);

-- Creating the subscription plan table
CREATE TABLE "subscriptionplan" (
    subscription_plan_id int PRIMARY KEY,
    name varchar(255),
    price decimal(10,2),
    description text
);

-- Creating the payment table
CREATE TABLE "payment" (
    payment_id int PRIMARY KEY,
    user_id int,
    amount decimal(10,2),
    date date,
    method varchar(50),
    FOREIGN KEY (user_id) REFERENCES "user"(userid)
);


```

the code(olap):
```
-- Dimension Tables
CREATE TABLE "dim_user" (
    userid int,
    username varchar(255),
    email varchar(255),
    startdate date,
    enddate date,
    iscurrent boolean,
    PRIMARY KEY (userid, startdate)
);

CREATE TABLE "dim_artist" (
    artistid int PRIMARY KEY,
    name varchar(255),
    genre varchar(255)
);

CREATE TABLE "dim_album" (
    albumid int PRIMARY KEY,
    title varchar(255),
    releasedate date
);

CREATE TABLE "dim_track" (
    trackid int PRIMARY KEY,
    title varchar(255),
    duration interval
);

CREATE TABLE "dim_time" (
    dateid int PRIMARY KEY,
    date date,
    month int,
    quarter int,
    year int
);

-- Fact Tables
-- Adjust Fact_Streaming to include StartDate
CREATE TABLE "fact_streaming" (
    userid int,
    startdate date,
    trackid int,
    dateid int,
    playcount int,
    listeningtime int,
    FOREIGN KEY (userid, startdate) REFERENCES "dim_user" (userid, startdate),
    FOREIGN KEY (trackid) REFERENCES "dim_track" (trackid),
    FOREIGN KEY (dateid) REFERENCES "dim_time" (dateid)
);

-- Adjust Fact_Subscription to include StartDate
CREATE TABLE "fact_subscription" (
    userid int,
    startdate date,
    dateid int,
    subscriptionplanid int,
    monthlyfee decimal(10,2),
    FOREIGN KEY (userid, startdate) REFERENCES "dim_user" (userid, startdate),
    FOREIGN KEY (dateid) REFERENCES "dim_time" (dateid)
);

CREATE INDEX idx_user ON "fact_streaming"(userid);
CREATE INDEX idx_track ON "fact_streaming"(trackid);
CREATE INDEX idx_date ON "fact_streaming"(dateid);
CREATE INDEX idx_subscription_date ON "fact_subscription"(dateid);
CREATE INDEX idx_subscription_user ON "fact_subscription"(userid);


```

HERE ARE THE CREDENTIALS FOR POSTGRES:
oltp_engine = create_engine(f"postgresql://postgres:frog2003@localhost:5432/oltp")
olap_engine = create_engine(f"postgresql://postgres:frog2003@localhost:5432/olap")